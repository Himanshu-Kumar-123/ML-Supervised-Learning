{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.2-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "\u001b[2K  Attempting uninstall: pytz\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\n",
      "\u001b[2K    Uninstalling pytz-2025.2:\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
      "\u001b[2K  Attempting uninstall: tzdata━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/6\u001b[0m [pytz]\n",
      "\u001b[2K    Found existing installation: tzdata 2025.20m \u001b[32m0/6\u001b[0m [pytz]\n",
      "\u001b[2K    Uninstalling tzdata-2025.2:━━━━━━━━━━━━━\u001b[0m \u001b[32m0/6\u001b[0m [pytz]\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.2\u001b[0m \u001b[32m0/6\u001b[0m [pytz]\n",
      "\u001b[2K  Attempting uninstall: sixm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling six-1.17.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/6\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: numpy 2.1.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling numpy-2.1.3:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.1.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m3/6\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Found existing installation: pandas 1.5.3[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [python-dateutil]\n",
      "\u001b[2K    Uninstalling pandas-1.5.3:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [python-dateutil]\n",
      "\u001b[2K      Successfully uninstalled pandas-1.5.3m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4/6\u001b[0m [python-dateutil]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [pandas]2m5/6\u001b[0m [pandas]util]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 pandas-2.3.2 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVGRgX3_XFsu"
   },
   "source": [
    "## UseCase Intro: Employee Attrition\n",
    "## You are a Data Scientist working at a Jio\n",
    "\n",
    "- The company is facing a huge problem of employee attrition\n",
    "- Your task is to help the company find a solution to this problem.\n",
    "\n",
    "#### Why is attrition a problem?\n",
    "\n",
    "  - A new employee asks for more compensation\n",
    "  - Training of new employees\n",
    "  - Lots of time and resources required for searching a new candidate\n",
    "\n",
    "#### What can be done to solve the problem ?\n",
    "\n",
    "1. Identify the employees who may leave in future.\n",
    "  - Targeted approaches can be undertaken to retain such employees.\n",
    "  - These might include addressing their problems with the company and so on ...\n",
    "\n",
    "2. Help identify the key indicators/factors leading to an employee leaving.\n",
    "  - #### What all reasons can you think of contributing to attrition ?\n",
    "    - Forcing employees to come to office daily\n",
    "    - Unhealthy culture etc\n",
    "  - Identifying these key factors helps in taking better measures to improve employee retention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WLEr_32hutd0"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RuQ2-hwzW4N"
   },
   "source": [
    "### Now lets import our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "tC34Fdu3vlNr",
    "outputId": "72d82fcd-b190-414f-8dfe-9680b73c66b4"
   },
   "outputs": [],
   "source": [
    "!gdown 16KtxSt_QEGQvfluEaMls5cCHPwhRXgCk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvn-Bc7ywh6z",
    "outputId": "a64fc7f2-42e5-4044-b1eb-f2a1dae5d7e1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR-Employee-Attrition.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "7aoTdNEKwj0c",
    "outputId": "4e671b8b-949d-47cb-855d-249e2aab1a56"
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfdL1YGbwn6V"
   },
   "source": [
    "#### What can we see from this info ?\n",
    "- The dataset has around 1500 samples\n",
    "- It contains information about :\n",
    "\n",
    "    1. Employee demographics\\\n",
    "     Eg: Age, Gender, Marital Status\n",
    "\n",
    "    2. Employee work-life\\\n",
    "     Eg: Working hours, job satisfaction etc\n",
    "\n",
    "#### How can we use this information for our problem ?\n",
    "\n",
    "To understand this lets analyze the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVF29Tt1zzzv"
   },
   "source": [
    "### EDA\n",
    "\n",
    "First lets try to find their ditsributions\n",
    "\n",
    "#### How can we do that ?\n",
    "- Plotting their histograms\n",
    "- Recall why we do that ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I2m9P4KJw-uM",
    "outputId": "94f3e35c-e1d1-42f8-ee4b-7346c6406c43"
   },
   "outputs": [],
   "source": [
    "df.hist(figsize = (20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssHZOtT0xDwZ"
   },
   "source": [
    "#### What can we observe from these plots ?\n",
    "\n",
    "1. Many histograms are tail-heavy;\n",
    "\n",
    "  - Lot of attributes are right-skewed\\\n",
    " (e.g. MonthlyIncome DistanceFromHome, YearsAtCompany)\n",
    "\n",
    "  - Data transformation methods **may be** required for standardisation\n",
    "    - Recall why standardisation is preferred ?\n",
    "\n",
    "2. Some features seem to have normal distributions\n",
    "\n",
    "  - Eg: Age:\n",
    "    - Slightly right-skewed normal distribution\n",
    "    - Bulk of the staff between 25 and 45 years old\n",
    "\n",
    "3. Some features are constant\n",
    "\n",
    "  - Eg: EmployeeCount and StandardHours are constant values for all employees.\n",
    "\n",
    "  - They're likely to be redundant features.\n",
    "\n",
    "  - #### How can these features contribute to our problem ?\n",
    "    - Constant features are not in any way useful for predictions\n",
    "    - So we can drop these features from the dataset\n",
    "\n",
    "4. Some features seem to be uniformly distributed.\n",
    "\n",
    "  - Eg: EmployeeNumber\n",
    "\n",
    "  - **Uniformly distributed and constant features won't contribute** to our analysis. Why?\n",
    "    - Each value is equally likely to occur\n",
    "\n",
    "  - #### So what should we do ?\n",
    "    - We can drop these features from our dataset\n",
    "\n",
    "5. Some features are categorical i.e **binomially/multinomially distributed**\n",
    "\n",
    "  - Eg: WorkLifeBalance, StockOptionLevel etc\n",
    "\n",
    "  - #### Can we use these features directly in our problem ?\n",
    "    - No. They willl first have to be encoded\n",
    "\n",
    "  - #### Recall which encoding has to be used for which features\n",
    "\n",
    "    - Binary Encoding (0/1) : Features with only 2 unique values\n",
    "\n",
    "    - Label Encoding (0, 1, 2, 3 ....) :  More than 2 unique values having a particular order\n",
    "\n",
    "  - OneHot Encoding ([0 0 0 1], ...) : More than 2 unique values having no order\n",
    "\n",
    "  - Target encoding ([0.1, 0.33, .....)] : Features with a lot of unique vals having no order\n",
    "\n",
    "\n",
    "7. We can also see from these features that their ranges vary a lot\n",
    "\n",
    "  - Recall why different feature scales can be a problem\n",
    "\n",
    "  - We will deal with this problem later\n",
    "\n",
    "First, lets remove the features that won't contribute to our analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "axsGv90oyA5-"
   },
   "outputs": [],
   "source": [
    "df.drop(['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzKoDCL5yH4i"
   },
   "source": [
    "Now lets encode our categorical features\n",
    "\n",
    "#### Which encoding technique should we use ?\n",
    "\n",
    "  - It depends upon:\n",
    "    - Number of unique values a feature has\n",
    "    - If there is a sequence between the feature vals\n",
    "\n",
    "Lets first check how many unique values each feature has\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WFrLLGsyOMP",
    "outputId": "b196ab1a-c6de-4be4-8d39-af5d46077d27"
   },
   "outputs": [],
   "source": [
    "def unique_vals(col):\n",
    "\n",
    "  if col.dtype == \"object\":\n",
    "\n",
    "    print(f'{col.name}: {col.nunique()}')\n",
    "\n",
    "df.apply(lambda col: unique_vals(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMlvVUhEyP_X"
   },
   "source": [
    "#### On basis of this info, which encoding technique should we use ?\n",
    "\n",
    " - We will use binary encoding for features with 2 or less unique val.\n",
    " - For features < 6 unique vals we will use OneHot encoding\n",
    " - Rest of the categorical features will be Target encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciOy5RLpyX1j",
    "outputId": "ca7ad798-6e12-4312-a8fd-ba7dbf3ca669"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "def label_encode(ser):\n",
    "\n",
    "    if ser.dtype==\"object\" and ser.nunique() <= 2:\n",
    "      print(ser.name)\n",
    "\n",
    "      le.fit(ser)\n",
    "      ser = le.transform(ser)\n",
    "\n",
    "    return ser\n",
    "\n",
    "df = df.apply(lambda col: label_encode(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "59_oreShh0wn"
   },
   "outputs": [],
   "source": [
    "# convert rest of categorical variable into dummy\n",
    "df = pd.get_dummies(df, columns = [\"BusinessTravel\", \"Department\", \"MaritalStatus\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "DAn4kyOFyZtk",
    "outputId": "2da503e5-7101-40fd-baf1-a542f1c83626"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVHv_JnyyeBN"
   },
   "source": [
    "#### Lets analyse the target feature now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZ6whOWEyfSq",
    "outputId": "e922128e-4a06-4df3-b51c-749ff04824de"
   },
   "outputs": [],
   "source": [
    "target = df['Attrition'].copy()\n",
    "df = df.drop([\"Attrition\"], axis = 1)\n",
    "type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTBKG1DLygtB",
    "outputId": "978a0431-9487-4bcf-c756-59b6123ab078"
   },
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkMLqPngyifo"
   },
   "source": [
    "#### What can we infer from this info ?\n",
    "  - The dataset is extremely imbalanced\n",
    "  - Recall how we deal with imbalanced data\n",
    "\n",
    "For this dataset we will use SMOTE oversampling technique to balance the data\n",
    "\n",
    "But SMOTE is applied only to training set\n",
    "\n",
    "So we need to split the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lOELDk7ykdP"
   },
   "source": [
    "#### In what sets should we split it ?\n",
    "\n",
    "  - Train/test set\n",
    "\n",
    "  - #### Why not create a validation set ?\n",
    "    - We already have less amount of data\n",
    "    - And we want to train the model with max possible data\n",
    "    - So we will use K-Fold cross validation instead\n",
    "\n",
    "#### What ratios should we use for splitting ?\n",
    "  - 80%/20% for train/test looks enough\n",
    "\n",
    "Lets split the dataset now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0N_VoTs2ynD5",
    "outputId": "fcda00c8-a1c9-4da2-e87e-b08fde6fab1e"
   },
   "outputs": [],
   "source": [
    "# Since we have class imbalance (i.e. more employees with turnover=0 than turnover=1)\n",
    "# let's use stratify=y to maintain the same ratio as in the training dataset when splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,\n",
    "                                                    target,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=7,\n",
    "                                                    stratify=target)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "xznMkA34Se0n",
    "outputId": "11076294-e812-43c0-87d6-c5e53ccd93c2"
   },
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbjW1vAMy0s0"
   },
   "source": [
    "Now we will first perform target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvJg5_AGy1mz",
    "outputId": "c7e474e9-8e65-48f8-87ac-624c46ec66d1"
   },
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnLfYTBwy4IV",
    "outputId": "63fc9f31-ab90-4a9d-b996-b3b069fb49de"
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "ce_target = ce.TargetEncoder(cols = ['EducationField', 'JobRole'])\n",
    "X_train = ce_target.fit_transform(X_train, y_train)\n",
    "X_test = ce_target.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quXsTpdSsfql"
   },
   "source": [
    "### Upsampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofi_wcARy5qy",
    "outputId": "ad6d948d-1723-4ee3-a5a8-67f091758691"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smt = SMOTE()\n",
    "X_sm, y_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy1of3kAiEwj",
    "outputId": "52f17ab2-5094-4455-a5c9-0a12c5b6b5e3"
   },
   "outputs": [],
   "source": [
    "X_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "eqL55xKqwBsm",
    "outputId": "b49fda4c-fbe5-4f38-b23e-8f7a2c5cc277"
   },
   "outputs": [],
   "source": [
    "X_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjutnEWjaXGz"
   },
   "source": [
    "### Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "YK15a4m5aZmd",
    "outputId": "9f13fe2c-4dff-41ea-8272-b3b4d5b7eff7"
   },
   "outputs": [],
   "source": [
    "!gdown 19L3rYatfhbBL1r5MHrv-p_oM2wlvrhqk\n",
    "!gdown 1OHLKJwA3qZopKPvlKoRldM6BvA1A4dYF\n",
    "!gdown 1N7O_fWCTJLu8SIa_paKcDEzllgpMk8sK\n",
    "!gdown 12Bh2AN8LcZAlg20ehpQrEWccUDaSdsOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lLOv-ppuaas8"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load data (deserialize)\n",
    "with open('preprocessed_X_sm.pickle', 'rb') as handle:\n",
    "    X_sm = pickle.load(handle)\n",
    "\n",
    "with open('X_test.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "\n",
    "with open('y_sm.pickle', 'rb') as handle:\n",
    "    y_sm = pickle.load(handle)\n",
    "\n",
    "with open('y_test.pickle', 'rb') as handle:\n",
    "    y_test = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
